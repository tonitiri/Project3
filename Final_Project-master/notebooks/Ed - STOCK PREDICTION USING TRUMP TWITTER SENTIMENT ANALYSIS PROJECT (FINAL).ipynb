{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOCK PREDICTION USING TWITTER SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing machine learning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import matplotlib.pyplot as mlpt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing library to fetch data from twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079888205351145472</td>\n",
       "      <td>HAPPY NEW YEAR! https://t.co/bHoPDPQ7G6</td>\n",
       "      <td>2018-12-31 23:53:06+00:00</td>\n",
       "      <td>33548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079830268708556800</td>\n",
       "      <td>....Senator Schumer, more than a year longer t...</td>\n",
       "      <td>2018-12-31 20:02:52+00:00</td>\n",
       "      <td>17456</td>\n",
       "      <td>25073877.0</td>\n",
       "      <td>65069</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079830267274108928</td>\n",
       "      <td>Heads of countries are calling wanting to know...</td>\n",
       "      <td>2018-12-31 20:02:52+00:00</td>\n",
       "      <td>21030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76721</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079763923845419008</td>\n",
       "      <td>It’s incredible how Democrats can all use thei...</td>\n",
       "      <td>2018-12-31 15:39:15+00:00</td>\n",
       "      <td>29610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127485</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079763419908243456</td>\n",
       "      <td>I’m in the Oval Office. Democrats, come back f...</td>\n",
       "      <td>2018-12-31 15:37:14+00:00</td>\n",
       "      <td>30957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132439</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6110</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>815449868739211264</td>\n",
       "      <td>RT @DonaldJTrumpJr: Happy new year everyone. #...</td>\n",
       "      <td>2017-01-01 06:49:33+00:00</td>\n",
       "      <td>6847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6111</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>815433444591304704</td>\n",
       "      <td>RT @EricTrump: 2016 was such an incredible yea...</td>\n",
       "      <td>2017-01-01 05:44:17+00:00</td>\n",
       "      <td>6941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6112</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>815433217595547648</td>\n",
       "      <td>RT @Reince: Happy New Year + God's blessings t...</td>\n",
       "      <td>2017-01-01 05:43:23+00:00</td>\n",
       "      <td>7144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6113</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>815432169464197120</td>\n",
       "      <td>RT @DanScavino: On behalf of our next #POTUS &amp;...</td>\n",
       "      <td>2017-01-01 05:39:13+00:00</td>\n",
       "      <td>5548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6114</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>815422340540547072</td>\n",
       "      <td>TO ALL AMERICANS-\\n#HappyNewYear &amp;amp; many bl...</td>\n",
       "      <td>2017-01-01 05:00:10+00:00</td>\n",
       "      <td>32665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126230</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6115 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  source               id_str  \\\n",
       "0     Twitter for iPhone  1079888205351145472   \n",
       "1     Twitter for iPhone  1079830268708556800   \n",
       "2     Twitter for iPhone  1079830267274108928   \n",
       "3     Twitter for iPhone  1079763923845419008   \n",
       "4     Twitter for iPhone  1079763419908243456   \n",
       "...                  ...                  ...   \n",
       "6110  Twitter for iPhone   815449868739211264   \n",
       "6111  Twitter for iPhone   815433444591304704   \n",
       "6112  Twitter for iPhone   815433217595547648   \n",
       "6113  Twitter for iPhone   815432169464197120   \n",
       "6114  Twitter for iPhone   815422340540547072   \n",
       "\n",
       "                                                   text  \\\n",
       "0               HAPPY NEW YEAR! https://t.co/bHoPDPQ7G6   \n",
       "1     ....Senator Schumer, more than a year longer t...   \n",
       "2     Heads of countries are calling wanting to know...   \n",
       "3     It’s incredible how Democrats can all use thei...   \n",
       "4     I’m in the Oval Office. Democrats, come back f...   \n",
       "...                                                 ...   \n",
       "6110  RT @DonaldJTrumpJr: Happy new year everyone. #...   \n",
       "6111  RT @EricTrump: 2016 was such an incredible yea...   \n",
       "6112  RT @Reince: Happy New Year + God's blessings t...   \n",
       "6113  RT @DanScavino: On behalf of our next #POTUS &...   \n",
       "6114  TO ALL AMERICANS-\\n#HappyNewYear &amp; many bl...   \n",
       "\n",
       "                    created_at  retweet_count  in_reply_to_user_id_str  \\\n",
       "0    2018-12-31 23:53:06+00:00          33548                      NaN   \n",
       "1    2018-12-31 20:02:52+00:00          17456               25073877.0   \n",
       "2    2018-12-31 20:02:52+00:00          21030                      NaN   \n",
       "3    2018-12-31 15:39:15+00:00          29610                      NaN   \n",
       "4    2018-12-31 15:37:14+00:00          30957                      NaN   \n",
       "...                        ...            ...                      ...   \n",
       "6110 2017-01-01 06:49:33+00:00           6847                      NaN   \n",
       "6111 2017-01-01 05:44:17+00:00           6941                      NaN   \n",
       "6112 2017-01-01 05:43:23+00:00           7144                      NaN   \n",
       "6113 2017-01-01 05:39:13+00:00           5548                      NaN   \n",
       "6114 2017-01-01 05:00:10+00:00          32665                      NaN   \n",
       "\n",
       "      favorite_count  is_retweet  \n",
       "0             136012       False  \n",
       "1              65069       False  \n",
       "2              76721       False  \n",
       "3             127485       False  \n",
       "4             132439       False  \n",
       "...              ...         ...  \n",
       "6110               0        True  \n",
       "6111               0        True  \n",
       "6112               0        True  \n",
       "6113               0        True  \n",
       "6114          126230       False  \n",
       "\n",
       "[6115 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tweets into a dataframe\n",
    "df18 = pd.read_json(os.path.join('condensed_2018.json'))\n",
    "df17 = pd.read_json(os.path.join('condensed_2017.json'))\n",
    "read_stock_p = pd.read_csv(os.path.join('dow.csv'))\n",
    "frames = [df18, df17]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "# Reset index\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop retweets\n",
    "result = result[~result.text.str.startswith('RT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.rename(columns={\"text\": \"Tweets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id_str</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079888205351145472</td>\n",
       "      <td>HAPPY NEW YEAR! https://t.co/bHoPDPQ7G6</td>\n",
       "      <td>2018-12-31 23:53:06+00:00</td>\n",
       "      <td>33548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079830268708556800</td>\n",
       "      <td>....Senator Schumer, more than a year longer t...</td>\n",
       "      <td>2018-12-31 20:02:52+00:00</td>\n",
       "      <td>17456</td>\n",
       "      <td>25073877.0</td>\n",
       "      <td>65069</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079830267274108928</td>\n",
       "      <td>Heads of countries are calling wanting to know...</td>\n",
       "      <td>2018-12-31 20:02:52+00:00</td>\n",
       "      <td>21030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76721</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079763923845419008</td>\n",
       "      <td>It’s incredible how Democrats can all use thei...</td>\n",
       "      <td>2018-12-31 15:39:15+00:00</td>\n",
       "      <td>29610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127485</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079763419908243456</td>\n",
       "      <td>I’m in the Oval Office. Democrats, come back f...</td>\n",
       "      <td>2018-12-31 15:37:14+00:00</td>\n",
       "      <td>30957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132439</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5336</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815990335318982656</td>\n",
       "      <td>Various media outlets and pundits say that I t...</td>\n",
       "      <td>2017-01-02 18:37:10+00:00</td>\n",
       "      <td>9057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47285</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5337</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815989154555297792</td>\n",
       "      <td>@CNN just released a book called \"Unprecedente...</td>\n",
       "      <td>2017-01-02 18:32:29+00:00</td>\n",
       "      <td>3948</td>\n",
       "      <td>759251.0</td>\n",
       "      <td>13862</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5338</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815973752785793024</td>\n",
       "      <td>Chicago murder rate is record setting - 4,331 ...</td>\n",
       "      <td>2017-01-02 17:31:17+00:00</td>\n",
       "      <td>17411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63340</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5339</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815930688889352192</td>\n",
       "      <td>Well, the New Year begins. We will, together, ...</td>\n",
       "      <td>2017-01-02 14:40:10+00:00</td>\n",
       "      <td>29248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124024</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5340</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>815422340540547072</td>\n",
       "      <td>TO ALL AMERICANS-\\n#HappyNewYear &amp;amp; many bl...</td>\n",
       "      <td>2017-01-01 05:00:10+00:00</td>\n",
       "      <td>32665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126230</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   source               id_str  \\\n",
       "0      Twitter for iPhone  1079888205351145472   \n",
       "1      Twitter for iPhone  1079830268708556800   \n",
       "2      Twitter for iPhone  1079830267274108928   \n",
       "3      Twitter for iPhone  1079763923845419008   \n",
       "4      Twitter for iPhone  1079763419908243456   \n",
       "...                   ...                  ...   \n",
       "5336  Twitter for Android   815990335318982656   \n",
       "5337  Twitter for Android   815989154555297792   \n",
       "5338  Twitter for Android   815973752785793024   \n",
       "5339  Twitter for Android   815930688889352192   \n",
       "5340   Twitter for iPhone   815422340540547072   \n",
       "\n",
       "                                                 Tweets  \\\n",
       "0               HAPPY NEW YEAR! https://t.co/bHoPDPQ7G6   \n",
       "1     ....Senator Schumer, more than a year longer t...   \n",
       "2     Heads of countries are calling wanting to know...   \n",
       "3     It’s incredible how Democrats can all use thei...   \n",
       "4     I’m in the Oval Office. Democrats, come back f...   \n",
       "...                                                 ...   \n",
       "5336  Various media outlets and pundits say that I t...   \n",
       "5337  @CNN just released a book called \"Unprecedente...   \n",
       "5338  Chicago murder rate is record setting - 4,331 ...   \n",
       "5339  Well, the New Year begins. We will, together, ...   \n",
       "5340  TO ALL AMERICANS-\\n#HappyNewYear &amp; many bl...   \n",
       "\n",
       "                    created_at  retweet_count  in_reply_to_user_id_str  \\\n",
       "0    2018-12-31 23:53:06+00:00          33548                      NaN   \n",
       "1    2018-12-31 20:02:52+00:00          17456               25073877.0   \n",
       "2    2018-12-31 20:02:52+00:00          21030                      NaN   \n",
       "3    2018-12-31 15:39:15+00:00          29610                      NaN   \n",
       "4    2018-12-31 15:37:14+00:00          30957                      NaN   \n",
       "...                        ...            ...                      ...   \n",
       "5336 2017-01-02 18:37:10+00:00           9057                      NaN   \n",
       "5337 2017-01-02 18:32:29+00:00           3948                 759251.0   \n",
       "5338 2017-01-02 17:31:17+00:00          17411                      NaN   \n",
       "5339 2017-01-02 14:40:10+00:00          29248                      NaN   \n",
       "5340 2017-01-01 05:00:10+00:00          32665                      NaN   \n",
       "\n",
       "      favorite_count  is_retweet  \n",
       "0             136012       False  \n",
       "1              65069       False  \n",
       "2              76721       False  \n",
       "3             127485       False  \n",
       "4             132439       False  \n",
       "...              ...         ...  \n",
       "5336           47285       False  \n",
       "5337           13862       False  \n",
       "5338           63340       False  \n",
       "5339          124024       False  \n",
       "5340          126230       False  \n",
       "\n",
       "[5341 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result['created_at'].apply(lambda x: x.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"Date\"] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id_str</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079888205351145472</td>\n",
       "      <td>HAPPY NEW YEAR! https://t.co/bHoPDPQ7G6</td>\n",
       "      <td>2018-12-31 23:53:06+00:00</td>\n",
       "      <td>33548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136012</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079830268708556800</td>\n",
       "      <td>....Senator Schumer, more than a year longer t...</td>\n",
       "      <td>2018-12-31 20:02:52+00:00</td>\n",
       "      <td>17456</td>\n",
       "      <td>25073877.0</td>\n",
       "      <td>65069</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079830267274108928</td>\n",
       "      <td>Heads of countries are calling wanting to know...</td>\n",
       "      <td>2018-12-31 20:02:52+00:00</td>\n",
       "      <td>21030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76721</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079763923845419008</td>\n",
       "      <td>It’s incredible how Democrats can all use thei...</td>\n",
       "      <td>2018-12-31 15:39:15+00:00</td>\n",
       "      <td>29610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127485</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079763419908243456</td>\n",
       "      <td>I’m in the Oval Office. Democrats, come back f...</td>\n",
       "      <td>2018-12-31 15:37:14+00:00</td>\n",
       "      <td>30957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132439</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5336</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815990335318982656</td>\n",
       "      <td>Various media outlets and pundits say that I t...</td>\n",
       "      <td>2017-01-02 18:37:10+00:00</td>\n",
       "      <td>9057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47285</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5337</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815989154555297792</td>\n",
       "      <td>@CNN just released a book called \"Unprecedente...</td>\n",
       "      <td>2017-01-02 18:32:29+00:00</td>\n",
       "      <td>3948</td>\n",
       "      <td>759251.0</td>\n",
       "      <td>13862</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5338</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815973752785793024</td>\n",
       "      <td>Chicago murder rate is record setting - 4,331 ...</td>\n",
       "      <td>2017-01-02 17:31:17+00:00</td>\n",
       "      <td>17411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63340</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5339</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815930688889352192</td>\n",
       "      <td>Well, the New Year begins. We will, together, ...</td>\n",
       "      <td>2017-01-02 14:40:10+00:00</td>\n",
       "      <td>29248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124024</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5340</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>815422340540547072</td>\n",
       "      <td>TO ALL AMERICANS-\\n#HappyNewYear &amp;amp; many bl...</td>\n",
       "      <td>2017-01-01 05:00:10+00:00</td>\n",
       "      <td>32665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126230</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   source               id_str  \\\n",
       "0      Twitter for iPhone  1079888205351145472   \n",
       "1      Twitter for iPhone  1079830268708556800   \n",
       "2      Twitter for iPhone  1079830267274108928   \n",
       "3      Twitter for iPhone  1079763923845419008   \n",
       "4      Twitter for iPhone  1079763419908243456   \n",
       "...                   ...                  ...   \n",
       "5336  Twitter for Android   815990335318982656   \n",
       "5337  Twitter for Android   815989154555297792   \n",
       "5338  Twitter for Android   815973752785793024   \n",
       "5339  Twitter for Android   815930688889352192   \n",
       "5340   Twitter for iPhone   815422340540547072   \n",
       "\n",
       "                                                 Tweets  \\\n",
       "0               HAPPY NEW YEAR! https://t.co/bHoPDPQ7G6   \n",
       "1     ....Senator Schumer, more than a year longer t...   \n",
       "2     Heads of countries are calling wanting to know...   \n",
       "3     It’s incredible how Democrats can all use thei...   \n",
       "4     I’m in the Oval Office. Democrats, come back f...   \n",
       "...                                                 ...   \n",
       "5336  Various media outlets and pundits say that I t...   \n",
       "5337  @CNN just released a book called \"Unprecedente...   \n",
       "5338  Chicago murder rate is record setting - 4,331 ...   \n",
       "5339  Well, the New Year begins. We will, together, ...   \n",
       "5340  TO ALL AMERICANS-\\n#HappyNewYear &amp; many bl...   \n",
       "\n",
       "                    created_at  retweet_count  in_reply_to_user_id_str  \\\n",
       "0    2018-12-31 23:53:06+00:00          33548                      NaN   \n",
       "1    2018-12-31 20:02:52+00:00          17456               25073877.0   \n",
       "2    2018-12-31 20:02:52+00:00          21030                      NaN   \n",
       "3    2018-12-31 15:39:15+00:00          29610                      NaN   \n",
       "4    2018-12-31 15:37:14+00:00          30957                      NaN   \n",
       "...                        ...            ...                      ...   \n",
       "5336 2017-01-02 18:37:10+00:00           9057                      NaN   \n",
       "5337 2017-01-02 18:32:29+00:00           3948                 759251.0   \n",
       "5338 2017-01-02 17:31:17+00:00          17411                      NaN   \n",
       "5339 2017-01-02 14:40:10+00:00          29248                      NaN   \n",
       "5340 2017-01-01 05:00:10+00:00          32665                      NaN   \n",
       "\n",
       "      favorite_count  is_retweet        Date  \n",
       "0             136012       False  2018-12-31  \n",
       "1              65069       False  2018-12-31  \n",
       "2              76721       False  2018-12-31  \n",
       "3             127485       False  2018-12-31  \n",
       "4             132439       False  2018-12-31  \n",
       "...              ...         ...         ...  \n",
       "5336           47285       False  2017-01-02  \n",
       "5337           13862       False  2017-01-02  \n",
       "5338           63340       False  2017-01-02  \n",
       "5339          124024       False  2017-01-02  \n",
       "5340          126230       False  2017-01-01  \n",
       "\n",
       "[5341 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "result['Tweets'] = result['Tweets'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id_str</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079888205351145472</td>\n",
       "      <td>HAPPY NEW YEAR!</td>\n",
       "      <td>2018-12-31 23:53:06+00:00</td>\n",
       "      <td>33548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136012</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079830268708556800</td>\n",
       "      <td>....Senator Schumer, more than a year longer t...</td>\n",
       "      <td>2018-12-31 20:02:52+00:00</td>\n",
       "      <td>17456</td>\n",
       "      <td>25073877.0</td>\n",
       "      <td>65069</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079830267274108928</td>\n",
       "      <td>Heads of countries are calling wanting to know...</td>\n",
       "      <td>2018-12-31 20:02:52+00:00</td>\n",
       "      <td>21030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76721</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079763923845419008</td>\n",
       "      <td>It’s incredible how Democrats can all use thei...</td>\n",
       "      <td>2018-12-31 15:39:15+00:00</td>\n",
       "      <td>29610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127485</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1079763419908243456</td>\n",
       "      <td>I’m in the Oval Office. Democrats, come back f...</td>\n",
       "      <td>2018-12-31 15:37:14+00:00</td>\n",
       "      <td>30957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132439</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5336</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815990335318982656</td>\n",
       "      <td>Various media outlets and pundits say that I t...</td>\n",
       "      <td>2017-01-02 18:37:10+00:00</td>\n",
       "      <td>9057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47285</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5337</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815989154555297792</td>\n",
       "      <td>@CNN just released a book called \"Unprecedente...</td>\n",
       "      <td>2017-01-02 18:32:29+00:00</td>\n",
       "      <td>3948</td>\n",
       "      <td>759251.0</td>\n",
       "      <td>13862</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5338</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815973752785793024</td>\n",
       "      <td>Chicago murder rate is record setting - 4,331 ...</td>\n",
       "      <td>2017-01-02 17:31:17+00:00</td>\n",
       "      <td>17411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63340</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5339</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>815930688889352192</td>\n",
       "      <td>Well, the New Year begins. We will, together, ...</td>\n",
       "      <td>2017-01-02 14:40:10+00:00</td>\n",
       "      <td>29248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124024</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5340</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>815422340540547072</td>\n",
       "      <td>TO ALL AMERICANS-\\n#HappyNewYear &amp;amp; many bl...</td>\n",
       "      <td>2017-01-01 05:00:10+00:00</td>\n",
       "      <td>32665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126230</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   source               id_str  \\\n",
       "0      Twitter for iPhone  1079888205351145472   \n",
       "1      Twitter for iPhone  1079830268708556800   \n",
       "2      Twitter for iPhone  1079830267274108928   \n",
       "3      Twitter for iPhone  1079763923845419008   \n",
       "4      Twitter for iPhone  1079763419908243456   \n",
       "...                   ...                  ...   \n",
       "5336  Twitter for Android   815990335318982656   \n",
       "5337  Twitter for Android   815989154555297792   \n",
       "5338  Twitter for Android   815973752785793024   \n",
       "5339  Twitter for Android   815930688889352192   \n",
       "5340   Twitter for iPhone   815422340540547072   \n",
       "\n",
       "                                                 Tweets  \\\n",
       "0                                      HAPPY NEW YEAR!    \n",
       "1     ....Senator Schumer, more than a year longer t...   \n",
       "2     Heads of countries are calling wanting to know...   \n",
       "3     It’s incredible how Democrats can all use thei...   \n",
       "4     I’m in the Oval Office. Democrats, come back f...   \n",
       "...                                                 ...   \n",
       "5336  Various media outlets and pundits say that I t...   \n",
       "5337  @CNN just released a book called \"Unprecedente...   \n",
       "5338  Chicago murder rate is record setting - 4,331 ...   \n",
       "5339  Well, the New Year begins. We will, together, ...   \n",
       "5340  TO ALL AMERICANS-\\n#HappyNewYear &amp; many bl...   \n",
       "\n",
       "                    created_at  retweet_count  in_reply_to_user_id_str  \\\n",
       "0    2018-12-31 23:53:06+00:00          33548                      NaN   \n",
       "1    2018-12-31 20:02:52+00:00          17456               25073877.0   \n",
       "2    2018-12-31 20:02:52+00:00          21030                      NaN   \n",
       "3    2018-12-31 15:39:15+00:00          29610                      NaN   \n",
       "4    2018-12-31 15:37:14+00:00          30957                      NaN   \n",
       "...                        ...            ...                      ...   \n",
       "5336 2017-01-02 18:37:10+00:00           9057                      NaN   \n",
       "5337 2017-01-02 18:32:29+00:00           3948                 759251.0   \n",
       "5338 2017-01-02 17:31:17+00:00          17411                      NaN   \n",
       "5339 2017-01-02 14:40:10+00:00          29248                      NaN   \n",
       "5340 2017-01-01 05:00:10+00:00          32665                      NaN   \n",
       "\n",
       "      favorite_count  is_retweet        Date  \n",
       "0             136012       False  2018-12-31  \n",
       "1              65069       False  2018-12-31  \n",
       "2              76721       False  2018-12-31  \n",
       "3             127485       False  2018-12-31  \n",
       "4             132439       False  2018-12-31  \n",
       "...              ...         ...         ...  \n",
       "5336           47285       False  2017-01-02  \n",
       "5337           13862       False  2017-01-02  \n",
       "5338           63340       False  2017-01-02  \n",
       "5339          124024       False  2017-01-02  \n",
       "5340          126230       False  2017-01-01  \n",
       "\n",
       "[5341 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = result.filter(['Date', 'Tweets'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing special character from each tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if __name__ == '__main__':\n",
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# data.to_csv(\"Tweets.csv\")\n",
    "cdata=pd.DataFrame(columns=['Date','Tweets'])\n",
    "total=100\n",
    "index=0\n",
    "for index,row in data.iterrows():\n",
    "    stre=row[\"Tweets\"]\n",
    "    my_new_string = re.sub('[^ a-zA-Z0-9]', '', stre)\n",
    "    cdata.sort_index()\n",
    "    cdata.set_value(index,'Date',row[\"Date\"])\n",
    "    cdata.set_value(index,'Tweets',my_new_string)\n",
    "    index=index+1\n",
    "#print(cdata.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>HAPPY NEW YEAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Senator Schumer more than a year longer than a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Heads of countries are calling wanting to know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Its incredible how Democrats can all use their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Im in the Oval Office Democrats come back from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5336</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Various media outlets and pundits say that I t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5337</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>CNN just released a book called Unprecedented ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5338</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Chicago murder rate is record setting  4331 sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5339</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Well the New Year begins We will together MAKE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5340</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>TO ALL AMERICANSHappyNewYear amp many blessing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5341 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                             Tweets\n",
       "0     2018-12-31                                    HAPPY NEW YEAR \n",
       "1     2018-12-31  Senator Schumer more than a year longer than a...\n",
       "2     2018-12-31  Heads of countries are calling wanting to know...\n",
       "3     2018-12-31  Its incredible how Democrats can all use their...\n",
       "4     2018-12-31  Im in the Oval Office Democrats come back from...\n",
       "...          ...                                                ...\n",
       "5336  2017-01-02  Various media outlets and pundits say that I t...\n",
       "5337  2017-01-02  CNN just released a book called Unprecedented ...\n",
       "5338  2017-01-02  Chicago murder rate is record setting  4331 sh...\n",
       "5339  2017-01-02  Well the New Year begins We will together MAKE...\n",
       "5340  2017-01-01  TO ALL AMERICANSHappyNewYear amp many blessing...\n",
       "\n",
       "[5341 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the data with date and tweets, you can notice there are multiple tweets for each day. So we will club them together later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe where we will combine the tweets date wise and store into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdata=pd.DataFrame(columns=['Date','Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if __name__ == '__main__':\n",
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "indx=0\n",
    "get_tweet=\"\"\n",
    "for i in range(0,len(cdata)-1):\n",
    "    get_date=cdata.Date.iloc[i]\n",
    "    next_date=cdata.Date.iloc[i+1]\n",
    "    if(str(get_date)==str(next_date)):\n",
    "        get_tweet=get_tweet+cdata.Tweets.iloc[i]+\" \"\n",
    "    if(str(get_date)!=str(next_date)):\n",
    "        ccdata.set_value(indx,'Date',get_date)\n",
    "        ccdata.set_value(indx,'Tweets',get_tweet)\n",
    "        indx=indx+1\n",
    "        get_tweet=\" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the tweets has been clubbed as per their date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>HAPPY NEW YEAR  Senator Schumer more than a ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>President and Mrs Obama builthas a ten foot W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018 is being called THE YEAR OF THE WORKER b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>Thank you to Sean Parnell for the nice commen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>CNN amp others within the Fake News Universe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Monitoring the terrible situation in Florida ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>Toyota Motor said will build a new plant in B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>Jackie Evanchos album sales have skyrocketed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>I will be having a general news conference on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>China has been taking out massive amounts of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>711 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                             Tweets\n",
       "0    2018-12-31  HAPPY NEW YEAR  Senator Schumer more than a ye...\n",
       "1    2018-12-30   President and Mrs Obama builthas a ten foot W...\n",
       "2    2018-12-29   2018 is being called THE YEAR OF THE WORKER b...\n",
       "3    2018-12-28   Thank you to Sean Parnell for the nice commen...\n",
       "4    2018-12-27   CNN amp others within the Fake News Universe ...\n",
       "..          ...                                                ...\n",
       "706  2017-01-06   Monitoring the terrible situation in Florida ...\n",
       "707  2017-01-05   Toyota Motor said will build a new plant in B...\n",
       "708  2017-01-04   Jackie Evanchos album sales have skyrocketed ...\n",
       "709  2017-01-03   I will be having a general news conference on...\n",
       "710  2017-01-02   China has been taking out massive amounts of ...\n",
       "\n",
       "[711 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now to know the \"closing price\" of each day we will import STOCK PRICE DATA for UNITED AIRLINES from \"yahoo.finance\". We will consider \"Close\" price only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>19872.859375</td>\n",
       "      <td>19938.529297</td>\n",
       "      <td>19775.929688</td>\n",
       "      <td>19881.759766</td>\n",
       "      <td>19881.759766</td>\n",
       "      <td>339180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>19890.939453</td>\n",
       "      <td>19956.140625</td>\n",
       "      <td>19878.830078</td>\n",
       "      <td>19942.160156</td>\n",
       "      <td>19942.160156</td>\n",
       "      <td>280010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>19924.560547</td>\n",
       "      <td>19948.599609</td>\n",
       "      <td>19811.119141</td>\n",
       "      <td>19899.289063</td>\n",
       "      <td>19899.289063</td>\n",
       "      <td>269920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>19906.960938</td>\n",
       "      <td>19999.630859</td>\n",
       "      <td>19834.080078</td>\n",
       "      <td>19963.800781</td>\n",
       "      <td>19963.800781</td>\n",
       "      <td>277700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>19931.410156</td>\n",
       "      <td>19943.779297</td>\n",
       "      <td>19887.380859</td>\n",
       "      <td>19887.380859</td>\n",
       "      <td>19887.380859</td>\n",
       "      <td>287510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>22871.740234</td>\n",
       "      <td>23254.589844</td>\n",
       "      <td>22396.339844</td>\n",
       "      <td>22445.369141</td>\n",
       "      <td>22445.369141</td>\n",
       "      <td>900510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>22317.279297</td>\n",
       "      <td>22339.869141</td>\n",
       "      <td>21792.199219</td>\n",
       "      <td>21792.199219</td>\n",
       "      <td>21792.199219</td>\n",
       "      <td>308420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>21857.730469</td>\n",
       "      <td>22878.919922</td>\n",
       "      <td>21712.529297</td>\n",
       "      <td>22878.449219</td>\n",
       "      <td>22878.449219</td>\n",
       "      <td>433080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>22629.060547</td>\n",
       "      <td>23138.890625</td>\n",
       "      <td>22267.419922</td>\n",
       "      <td>23138.820313</td>\n",
       "      <td>23138.820313</td>\n",
       "      <td>407940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>23213.609375</td>\n",
       "      <td>23381.880859</td>\n",
       "      <td>22981.330078</td>\n",
       "      <td>23062.400391</td>\n",
       "      <td>23062.400391</td>\n",
       "      <td>336510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close  \\\n",
       "0    2017-01-03  19872.859375  19938.529297  19775.929688  19881.759766   \n",
       "1    2017-01-04  19890.939453  19956.140625  19878.830078  19942.160156   \n",
       "2    2017-01-05  19924.560547  19948.599609  19811.119141  19899.289063   \n",
       "3    2017-01-06  19906.960938  19999.630859  19834.080078  19963.800781   \n",
       "4    2017-01-09  19931.410156  19943.779297  19887.380859  19887.380859   \n",
       "..          ...           ...           ...           ...           ...   \n",
       "496  2018-12-21  22871.740234  23254.589844  22396.339844  22445.369141   \n",
       "497  2018-12-24  22317.279297  22339.869141  21792.199219  21792.199219   \n",
       "498  2018-12-26  21857.730469  22878.919922  21712.529297  22878.449219   \n",
       "499  2018-12-27  22629.060547  23138.890625  22267.419922  23138.820313   \n",
       "500  2018-12-28  23213.609375  23381.880859  22981.330078  23062.400391   \n",
       "\n",
       "        Adj Close     Volume  \n",
       "0    19881.759766  339180000  \n",
       "1    19942.160156  280010000  \n",
       "2    19899.289063  269920000  \n",
       "3    19963.800781  277700000  \n",
       "4    19887.380859  287510000  \n",
       "..            ...        ...  \n",
       "496  22445.369141  900510000  \n",
       "497  21792.199219  308420000  \n",
       "498  22878.449219  433080000  \n",
       "499  23138.820313  407940000  \n",
       "500  23062.400391  336510000  \n",
       "\n",
       "[501 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "read_stock_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a \"Price\" column in our dataframe and fetching the stock price as per the date in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdata['Prices']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "indx=0\n",
    "for i in range (0,len(ccdata)):\n",
    "    for j in range (0,len(read_stock_p)):\n",
    "        get_tweet_date=ccdata.Date.iloc[i]\n",
    "        get_stock_date=read_stock_p.Date.iloc[j]\n",
    "        if(str(get_stock_date)==str(get_tweet_date)):\n",
    "            #print(get_stock_date,\" \",get_tweet_date)\n",
    "            ccdata.set_value(i,'Prices',int(read_stock_p.Close[j]))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prices are fetched but some entires are blank as close price might not be available for that day due to some reason (like holiday, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>HAPPY NEW YEAR  Senator Schumer more than a ye...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>President and Mrs Obama builthas a ten foot W...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018 is being called THE YEAR OF THE WORKER b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>Thank you to Sean Parnell for the nice commen...</td>\n",
       "      <td>23062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>CNN amp others within the Fake News Universe ...</td>\n",
       "      <td>23138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Monitoring the terrible situation in Florida ...</td>\n",
       "      <td>19963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>Toyota Motor said will build a new plant in B...</td>\n",
       "      <td>19899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>Jackie Evanchos album sales have skyrocketed ...</td>\n",
       "      <td>19942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>I will be having a general news conference on...</td>\n",
       "      <td>19881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>China has been taking out massive amounts of ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>711 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                             Tweets Prices\n",
       "0    2018-12-31  HAPPY NEW YEAR  Senator Schumer more than a ye...       \n",
       "1    2018-12-30   President and Mrs Obama builthas a ten foot W...       \n",
       "2    2018-12-29   2018 is being called THE YEAR OF THE WORKER b...       \n",
       "3    2018-12-28   Thank you to Sean Parnell for the nice commen...  23062\n",
       "4    2018-12-27   CNN amp others within the Fake News Universe ...  23138\n",
       "..          ...                                                ...    ...\n",
       "706  2017-01-06   Monitoring the terrible situation in Florida ...  19963\n",
       "707  2017-01-05   Toyota Motor said will build a new plant in B...  19899\n",
       "708  2017-01-04   Jackie Evanchos album sales have skyrocketed ...  19942\n",
       "709  2017-01-03   I will be having a general news conference on...  19881\n",
       "710  2017-01-02   China has been taking out massive amounts of ...       \n",
       "\n",
       "[711 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we take the mean for the close price and put it in the blank value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=0\n",
    "summ=0\n",
    "count=0\n",
    "for i in range(0,len(ccdata)):\n",
    "    if(ccdata.Prices.iloc[i]!=\"\"):\n",
    "        summ=summ+int(ccdata.Prices.iloc[i])\n",
    "        count=count+1\n",
    "mean=summ/count\n",
    "for i in range(0,len(ccdata)):\n",
    "    if(ccdata.Prices.iloc[i]==\"\"):\n",
    "        ccdata.Prices.iloc[i]=int(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now all the entries have some value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>HAPPY NEW YEAR  Senator Schumer more than a ye...</td>\n",
       "      <td>23381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>President and Mrs Obama builthas a ten foot W...</td>\n",
       "      <td>23381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018 is being called THE YEAR OF THE WORKER b...</td>\n",
       "      <td>23381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>Thank you to Sean Parnell for the nice commen...</td>\n",
       "      <td>23062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>CNN amp others within the Fake News Universe ...</td>\n",
       "      <td>23138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Monitoring the terrible situation in Florida ...</td>\n",
       "      <td>19963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>Toyota Motor said will build a new plant in B...</td>\n",
       "      <td>19899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>Jackie Evanchos album sales have skyrocketed ...</td>\n",
       "      <td>19942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>I will be having a general news conference on...</td>\n",
       "      <td>19881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>China has been taking out massive amounts of ...</td>\n",
       "      <td>23381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>711 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                             Tweets  Prices\n",
       "0    2018-12-31  HAPPY NEW YEAR  Senator Schumer more than a ye...   23381\n",
       "1    2018-12-30   President and Mrs Obama builthas a ten foot W...   23381\n",
       "2    2018-12-29   2018 is being called THE YEAR OF THE WORKER b...   23381\n",
       "3    2018-12-28   Thank you to Sean Parnell for the nice commen...   23062\n",
       "4    2018-12-27   CNN amp others within the Fake News Universe ...   23138\n",
       "..          ...                                                ...     ...\n",
       "706  2017-01-06   Monitoring the terrible situation in Florida ...   19963\n",
       "707  2017-01-05   Toyota Motor said will build a new plant in B...   19899\n",
       "708  2017-01-04   Jackie Evanchos album sales have skyrocketed ...   19942\n",
       "709  2017-01-03   I will be having a general news conference on...   19881\n",
       "710  2017-01-02   China has been taking out massive amounts of ...   23381\n",
       "\n",
       "[711 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making \"prices\" column as integer so mathematical operations could be performed easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccdata['Prices'] = ccdata['Prices'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding 4 new columns in our dataframe so that sentiment analysis could be performed.. Comp is \"Compound\" it will tell whether the statement is overall negative or positive. If it has negative value then it is negative, if it has positive value then it is positive. If it has value 0, then it is neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>HAPPY NEW YEAR  Senator Schumer more than a ye...</td>\n",
       "      <td>23381</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>President and Mrs Obama builthas a ten foot W...</td>\n",
       "      <td>23381</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018 is being called THE YEAR OF THE WORKER b...</td>\n",
       "      <td>23381</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>Thank you to Sean Parnell for the nice commen...</td>\n",
       "      <td>23062</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>CNN amp others within the Fake News Universe ...</td>\n",
       "      <td>23138</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Monitoring the terrible situation in Florida ...</td>\n",
       "      <td>19963</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>Toyota Motor said will build a new plant in B...</td>\n",
       "      <td>19899</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>Jackie Evanchos album sales have skyrocketed ...</td>\n",
       "      <td>19942</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>I will be having a general news conference on...</td>\n",
       "      <td>19881</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>China has been taking out massive amounts of ...</td>\n",
       "      <td>23381</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>711 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                             Tweets  Prices  \\\n",
       "0    2018-12-31  HAPPY NEW YEAR  Senator Schumer more than a ye...   23381   \n",
       "1    2018-12-30   President and Mrs Obama builthas a ten foot W...   23381   \n",
       "2    2018-12-29   2018 is being called THE YEAR OF THE WORKER b...   23381   \n",
       "3    2018-12-28   Thank you to Sean Parnell for the nice commen...   23062   \n",
       "4    2018-12-27   CNN amp others within the Fake News Universe ...   23138   \n",
       "..          ...                                                ...     ...   \n",
       "706  2017-01-06   Monitoring the terrible situation in Florida ...   19963   \n",
       "707  2017-01-05   Toyota Motor said will build a new plant in B...   19899   \n",
       "708  2017-01-04   Jackie Evanchos album sales have skyrocketed ...   19942   \n",
       "709  2017-01-03   I will be having a general news conference on...   19881   \n",
       "710  2017-01-02   China has been taking out massive amounts of ...   23381   \n",
       "\n",
       "    Comp Negative Neutral Positive  \n",
       "0                                   \n",
       "1                                   \n",
       "2                                   \n",
       "3                                   \n",
       "4                                   \n",
       "..   ...      ...     ...      ...  \n",
       "706                                 \n",
       "707                                 \n",
       "708                                 \n",
       "709                                 \n",
       "710                                 \n",
       "\n",
       "[711 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdata[\"Comp\"] = ''\n",
    "ccdata[\"Negative\"] = ''\n",
    "ccdata[\"Neutral\"] = ''\n",
    "ccdata[\"Positive\"] = ''\n",
    "ccdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading this package was essential to perform sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Ed/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This part of the code is responsible for assigning the polarity for each statement. That is how much positive, negative, neutral you statement is. And also assign the compound value that is overall sentiment of the statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if __name__ == '__main__':\n",
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import unicodedata\n",
    "sentiment_i_a = SentimentIntensityAnalyzer()\n",
    "for indexx, row in ccdata.T.iteritems():\n",
    "    try:\n",
    "        sentence_i = unicodedata.normalize('NFKD', ccdata.loc[indexx, 'Tweets'])\n",
    "        sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n",
    "        ccdata.set_value(indexx, 'Comp', sentence_sentiment['compound'])\n",
    "        ccdata.set_value(indexx, 'Negative', sentence_sentiment['neg'])\n",
    "        ccdata.set_value(indexx, 'Neutral', sentence_sentiment['neu'])\n",
    "        ccdata.set_value(indexx, 'Positive', sentence_sentiment['pos'])\n",
    "    except TypeError:\n",
    "        print (stocks_dataf.loc[indexx, 'Tweets'])\n",
    "        print (indexx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>HAPPY NEW YEAR  Senator Schumer more than a ye...</td>\n",
       "      <td>23381</td>\n",
       "      <td>-0.9391</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>President and Mrs Obama builthas a ten foot W...</td>\n",
       "      <td>23381</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018 is being called THE YEAR OF THE WORKER b...</td>\n",
       "      <td>23381</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>Thank you to Sean Parnell for the nice commen...</td>\n",
       "      <td>23062</td>\n",
       "      <td>-0.3262</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>CNN amp others within the Fake News Universe ...</td>\n",
       "      <td>23138</td>\n",
       "      <td>-0.9813</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Monitoring the terrible situation in Florida ...</td>\n",
       "      <td>19963</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>Toyota Motor said will build a new plant in B...</td>\n",
       "      <td>19899</td>\n",
       "      <td>0.4151</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>Jackie Evanchos album sales have skyrocketed ...</td>\n",
       "      <td>19942</td>\n",
       "      <td>-0.9513</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>I will be having a general news conference on...</td>\n",
       "      <td>19881</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>China has been taking out massive amounts of ...</td>\n",
       "      <td>23381</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>711 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                             Tweets  Prices  \\\n",
       "0    2018-12-31  HAPPY NEW YEAR  Senator Schumer more than a ye...   23381   \n",
       "1    2018-12-30   President and Mrs Obama builthas a ten foot W...   23381   \n",
       "2    2018-12-29   2018 is being called THE YEAR OF THE WORKER b...   23381   \n",
       "3    2018-12-28   Thank you to Sean Parnell for the nice commen...   23062   \n",
       "4    2018-12-27   CNN amp others within the Fake News Universe ...   23138   \n",
       "..          ...                                                ...     ...   \n",
       "706  2017-01-06   Monitoring the terrible situation in Florida ...   19963   \n",
       "707  2017-01-05   Toyota Motor said will build a new plant in B...   19899   \n",
       "708  2017-01-04   Jackie Evanchos album sales have skyrocketed ...   19942   \n",
       "709  2017-01-03   I will be having a general news conference on...   19881   \n",
       "710  2017-01-02   China has been taking out massive amounts of ...   23381   \n",
       "\n",
       "       Comp Negative Neutral Positive  \n",
       "0   -0.9391    0.139   0.745    0.116  \n",
       "1    0.9835     0.09   0.644    0.266  \n",
       "2    0.3644    0.105   0.786     0.11  \n",
       "3   -0.3262    0.089   0.829    0.082  \n",
       "4   -0.9813    0.133   0.779    0.088  \n",
       "..      ...      ...     ...      ...  \n",
       "706  0.9876    0.061   0.767    0.171  \n",
       "707  0.4151    0.116   0.749    0.135  \n",
       "708 -0.9513    0.145    0.78    0.075  \n",
       "709  0.6747    0.114   0.743    0.142  \n",
       "710  -0.954    0.207   0.661    0.132  \n",
       "\n",
       "[711 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ccdata.to_csv(ccdata.csv, sep='/,')\n",
    "export_csv = ccdata.to_csv (r'\\Users\\Edward Doris\\Desktop\\project3\\ccdata.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the percentage of postive and negative tweets, and plotting the PIE chart for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of positive tweets=  69.76090014064698\n",
      "% of negative tweets=  24.613220815752463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posi=0\n",
    "nega=0\n",
    "for i in range (0,len(ccdata)):\n",
    "    get_val=ccdata.Comp[i]\n",
    "    if(float(get_val)<(0)):\n",
    "        nega=nega+1\n",
    "    if(float(get_val>(0))):\n",
    "        posi=posi+1\n",
    "posper=(posi/(len(ccdata)))*100\n",
    "negper=(nega/(len(ccdata)))*100\n",
    "print(\"% of positive tweets= \",posper)\n",
    "print(\"% of negative tweets= \",negper)\n",
    "arr=np.asarray([posper,negper], dtype=int)\n",
    "mlpt.pie(arr,labels=['positive','negative'])\n",
    "mlpt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a new dataframe with necessary columns for providing machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=ccdata[['Date','Prices','Comp','Negative','Neutral','Positive']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>23381</td>\n",
       "      <td>-0.9391</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>23381</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>23381</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>23062</td>\n",
       "      <td>-0.3262</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>23138</td>\n",
       "      <td>-0.9813</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>19963</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>19899</td>\n",
       "      <td>0.4151</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>19942</td>\n",
       "      <td>-0.9513</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>19881</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>23381</td>\n",
       "      <td>-0.954</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>711 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Prices    Comp Negative Neutral Positive\n",
       "0    2018-12-31   23381 -0.9391    0.139   0.745    0.116\n",
       "1    2018-12-30   23381  0.9835     0.09   0.644    0.266\n",
       "2    2018-12-29   23381  0.3644    0.105   0.786     0.11\n",
       "3    2018-12-28   23062 -0.3262    0.089   0.829    0.082\n",
       "4    2018-12-27   23138 -0.9813    0.133   0.779    0.088\n",
       "..          ...     ...     ...      ...     ...      ...\n",
       "706  2017-01-06   19963  0.9876    0.061   0.767    0.171\n",
       "707  2017-01-05   19899  0.4151    0.116   0.749    0.135\n",
       "708  2017-01-04   19942 -0.9513    0.145    0.78    0.075\n",
       "709  2017-01-03   19881  0.6747    0.114   0.743    0.142\n",
       "710  2017-01-02   23381  -0.954    0.207   0.661    0.132\n",
       "\n",
       "[711 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing the dataset into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n",
      "/Users/Ed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_start_index = '0'\n",
    "train_end_index = '142'\n",
    "test_start_index = '143'\n",
    "test_end_index = '710'\n",
    "train = df_.ix[train_start_index : train_end_index]\n",
    "test = df_.ix[test_start_index:test_end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a 2D array that will store the Negative and Positive sentiment for Training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_list = []\n",
    "for date, row in train.T.iteritems():\n",
    "    sentiment_score = np.asarray([df_.loc[date, 'Negative'],df_.loc[date, 'Positive']])\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "numpy_df_train = np.asarray(sentiment_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.139 0.116]\n",
      " [0.09  0.266]\n",
      " [0.105 0.11 ]\n",
      " [0.089 0.082]\n",
      " [0.133 0.088]\n",
      " [0.    0.   ]\n",
      " [0.053 0.345]\n",
      " [0.077 0.149]\n",
      " [0.125 0.158]\n",
      " [0.133 0.156]\n",
      " [0.097 0.169]\n",
      " [0.113 0.15 ]\n",
      " [0.112 0.176]\n",
      " [0.138 0.172]\n",
      " [0.011 0.233]]\n"
     ]
    }
   ],
   "source": [
    "print(numpy_df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a 2D array that will store the Negative and Positive sentiment for Testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_list = []\n",
    "for date, row in test.T.iteritems():\n",
    "    sentiment_score = np.asarray([df_.loc[date, 'Negative'],df_.loc[date, 'Positive']])\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "numpy_df_test = np.asarray(sentiment_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.172 0.078]\n",
      " [0.133 0.164]\n",
      " [0.037 0.22 ]\n",
      " ...\n",
      " [0.145 0.075]\n",
      " [0.114 0.142]\n",
      " [0.207 0.132]]\n"
     ]
    }
   ],
   "source": [
    "print(numpy_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making 2 dataframe for Training and Testing \"Prices\". You can also make 1-D array for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Prices\n",
      "0    23381\n",
      "1    23381\n",
      "2    23381\n",
      "3    23062\n",
      "4    23138\n",
      "5    22878\n",
      "6    23381\n",
      "7    21792\n",
      "8    23381\n",
      "9    23381\n",
      "10   22445\n",
      "11   22859\n",
      "12   23323\n",
      "13   23675\n",
      "14   23592\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.DataFrame(train['Prices'])\n",
    "#y_train=[91,91,91,92,91,92,91]\n",
    "y_test = pd.DataFrame(test['Prices'])\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the sentiments(this acts as in independent value) and prices(this acts as a dependent value (like class-lables in iris dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/__main__.py\", line 16, in <module>\n",
      "    from pip._internal import main as _main  # isort:skip # noqa\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/_internal/__init__.py\", line 40, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/_internal/cli/autocompletion.py\", line 8, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/_internal/cli/main_parser.py\", line 11, in <module>\n",
      "    from pip._internal.commands import (\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/__init__.py\", line 9, in <module>\n",
      "    from pip._internal.commands.download import DownloadCommand\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/download.py\", line 10, in <module>\n",
      "    from pip._internal.operations.prepare import RequirementPreparer\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/prepare.py\", line 9, in <module>\n",
      "    from pip._internal.distributions import (\n",
      "  File \"/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/_internal/distributions/__init__.py\", line 1, in <module>\n",
      "    from pip._internal.distributions.source import SourceDistribution\n",
      "ImportError: cannot import name 'SourceDistribution' from 'pip._internal.distributions.source' (/Users/Ed/anaconda3/lib/python3.7/site-packages/pip/_internal/distributions/source/__init__.py)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install treeinterpreter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-6782a82a9134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# from sklearn.metrics import classification_report,confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_df_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# from treeinterpreter import treeinterpreter as ti\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(numpy_df_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, bias, contributions = ti.predict(rf, numpy_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing matplotlib library for plotting graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining index position for the test data. Making dataframe for the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.arange(int(test_start_index),int(test_end_index)+2)\n",
    "predictions_df_ = pd.DataFrame(data=prediction[0:], index = idx, columns=['Prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the graph for the Predicted_price VS Actual Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_df_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-156057d9af96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_df_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Prices\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"predicted_price\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Random Forest predicted prices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#predicted value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Indexes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stock Prices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Prices\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"actual_price\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#actual value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"random forest.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions_df_' is not defined"
     ]
    }
   ],
   "source": [
    "ax = predictions_df_.rename(columns={\"Prices\": \"predicted_price\"}).plot(title='Random Forest predicted prices')#predicted value\n",
    "ax.set_xlabel(\"Indexes\")\n",
    "ax.set_ylabel(\"Stock Prices\")\n",
    "fig = y_test.rename(columns={\"Prices\": \"actual_price\"}).plot(ax = ax).get_figure()#actual value\n",
    "fig.savefig(\"random forest.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(numpy_df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(numpy_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Since our dataset is very small and as you can see that fetching 600 tweets could only make data for just 10 days.Also the prediction is not very great in such small dataset. So we found this new dataset on internet which has the Text as \"Tweets\" and respective \"close price\" and \"Adjusted close price\".\n",
    "\n",
    "\n",
    "### Adjusted Close Price: An adjusted closing price is a stock's closing price on any given day of trading that has been amended to include any distributions and corporate actions that occurred at any time before the next day's open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_dataf = pd.read_pickle('C:\\\\Users\\\\anubh\\\\OneDrive\\\\Desktop\\\\Twitter_Dataset.pkl')\n",
    "stocks_dataf.columns=['closing_price','adj_close_price','Tweets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stocks_dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing dot (.) and space from the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
    "stocks_dataf = stocks_dataf[['adj_close_price', 'Tweets']]\n",
    "stocks_dataf['Tweets'] = stocks_dataf['Tweets'].map(lambda x: x.lstrip('.-'))\n",
    "stocks_dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making new dataframe and only considering \"Adjusted close price\". And date as index vlaue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = stocks_dataf[['adj_close_price']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe[\"Comp\"] = ''\n",
    "dataframe[\"Negative\"] = ''\n",
    "dataframe[\"Neutral\"] = ''\n",
    "dataframe[\"Positive\"] = ''\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import unicodedata\n",
    "sentiment_i_a = SentimentIntensityAnalyzer()\n",
    "for indexx, row in stocks_dataf.T.iteritems():\n",
    "    try:\n",
    "        sentence_i = unicodedata.normalize('NFKD', stocks_dataf.loc[indexx, 'Tweets'])\n",
    "        sentence_sentiment = sentiment_i_a.polarity_scores(sentence_i)\n",
    "        dataframe.set_value(indexx, 'Comp', sentence_sentiment['compound'])\n",
    "        dataframe.set_value(indexx, 'Negative', sentence_sentiment['neg'])\n",
    "        dataframe.set_value(indexx, 'Neutral', sentence_sentiment['neu'])\n",
    "        dataframe.set_value(indexx, 'Positive', sentence_sentiment['pos'])\n",
    "    except TypeError:\n",
    "        print (stocks_dataf.loc[indexx, 'Tweets'])\n",
    "        print (indexx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posi=0\n",
    "nega=0\n",
    "for i in range (0,len(dataframe)):\n",
    "    get_val=dataframe.Comp[i]\n",
    "    if(float(get_val)<(-0.99)):\n",
    "        nega=nega+1\n",
    "    if(float(get_val>(-0.99))):\n",
    "        posi=posi+1\n",
    "posper=(posi/(len(dataframe)))*100\n",
    "negper=(nega/(len(dataframe)))*100\n",
    "print(\"% of positive tweets= \",posper)\n",
    "print(\"% of negative tweets= \",negper)\n",
    "arr=np.asarray([posper,negper], dtype=int)\n",
    "mlpt.pie(arr,labels=['positive','negative'])\n",
    "mlpt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_start = '2007-01-01'\n",
    "train_data_end = '2014-12-31'\n",
    "test_data_start = '2015-01-01'\n",
    "test_data_end = '2016-12-31'\n",
    "train = dataframe.ix[train_data_start : train_data_end]\n",
    "test = dataframe.ix[test_data_start:test_data_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sentiments_score = []\n",
    "for date, row in train.T.iteritems():\n",
    "    sentiment_score = np.asarray([dataframe.loc[date, 'Comp']])\n",
    "    list_of_sentiments_score.append(sentiment_score)\n",
    "numpy_dataframe_train = np.asarray(list_of_sentiments_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sentiments_score = []\n",
    "for date, row in test.T.iteritems():\n",
    "    sentiment_score = np.asarray([dataframe.loc[date, 'Comp']])\n",
    "    list_of_sentiments_score.append(sentiment_score)\n",
    "numpy_dataframe_test = np.asarray(list_of_sentiments_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(train['adj_close_price'])\n",
    "y_test = pd.DataFrame(test['adj_close_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(numpy_dataframe_train, train['adj_close_price'])\n",
    "prediction=rf.predict(numpy_dataframe_test)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "idx = pd.date_range(test_data_start, test_data_end)\n",
    "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
    "predictions_df['adj_close_price'] = predictions_df['adj_close_price'].apply(np.int64)\n",
    "predictions_df['adj_close_price'] = predictions_df['adj_close_price'] + 4500\n",
    "predictions_df['actual_value'] = test['adj_close_price']\n",
    "predictions_df.columns = ['predicted_price', 'actual_price']\n",
    "predictions_df.plot()\n",
    "predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n",
    "test['adj_close_price']=test['adj_close_price'].apply(np.int64)\n",
    "#print(accuracy_score(test['adj_close_price'],predictions_df['predicted_price']))\n",
    "print(rf.score(numpy_dataframe_train, train['adj_close_price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', #'relu', the rectified linear unit function\n",
    "                     solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False)\n",
    "\"\"\"Hidden_Layer_Sizes: tuple, length = n_layers - 2, default (100,)\n",
    "The ith element represents the number of Neutralrons in the ith\n",
    "hidden layer.\"\"\"\n",
    "mlpc.fit(numpy_dataframe_train, train['adj_close_price'])   \n",
    "prediction = mlpc.predict(numpy_dataframe_test)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "idx = pd.date_range(test_data_start, test_data_end)\n",
    "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
    "predictions_df['adj_close_price'] = predictions_df['adj_close_price'].apply(np.int64)\n",
    "predictions_df['adj_close_price'] = predictions_df['adj_close_price'] +4500\n",
    "predictions_df['actual_value'] = test['adj_close_price']\n",
    "predictions_df.columns = ['predicted_price', 'actual_price']\n",
    "predictions_df.plot()\n",
    "predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n",
    "test['adj_close_price']=test['adj_close_price'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlpc.score(numpy_dataframe_train, train['adj_close_price']))\n",
    "#print(accuracy_score(test['adj_close_price'],predictions_df['predicted_price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(numpy_dataframe_train, train['adj_close_price'])   \n",
    "prediction = regr.predict(numpy_dataframe_test)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "idx = pd.date_range(test_data_start, test_data_end)\n",
    "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
    "predictions_df['adj_close_price'] = predictions_df['adj_close_price'].apply(np.int64)\n",
    "predictions_df['adj_close_price'] = predictions_df['adj_close_price'] + 4500\n",
    "predictions_df['actual_value'] = test['adj_close_price']\n",
    "predictions_df.columns = ['predicted_price', 'actual_price']\n",
    "predictions_df.plot()\n",
    "predictions_df['predicted_price'] = predictions_df['predicted_price'].apply(np.int64)\n",
    "test['adj_close_price']=test['adj_close_price'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as tree_interpreter\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime, timedelta\n",
    "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "prediction_list = []\n",
    "for year in years:\n",
    "    train_data_start = str(year) + '-01-01'\n",
    "    train_data_end = str(year) + '-08-31'\n",
    "    test_data_start = str(year) + '-09-01'\n",
    "    test_data_end = str(year) + '-12-31'\n",
    "    train = dataframe.ix[train_data_start : train_data_end]\n",
    "    test = dataframe.ix[test_data_start:test_data_end]\n",
    "    \n",
    "    list_of_sentiments_score = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        sentiment_score = np.asarray([dataframe.loc[date, 'Comp'],dataframe.loc[date, 'Negative'],dataframe.loc[date, 'Neutral'],dataframe.loc[date, 'Positive']])\n",
    "        list_of_sentiments_score.append(sentiment_score)\n",
    "    numpy_dataframe_train = np.asarray(list_of_sentiments_score)\n",
    "    list_of_sentiments_score = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        sentiment_score = np.asarray([dataframe.loc[date, 'Comp'],dataframe.loc[date, 'Negative'],dataframe.loc[date, 'Neutral'],dataframe.loc[date, 'Positive']])\n",
    "        list_of_sentiments_score.append(sentiment_score)\n",
    "    numpy_dataframe_test = np.asarray(list_of_sentiments_score)\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=25)\n",
    "    rf.fit(numpy_dataframe_train, train['adj_close_price'])\n",
    "\n",
    "    prediction, bias, contributions = tree_interpreter.predict(rf, numpy_dataframe_test)\n",
    "    prediction_list.append(prediction)\n",
    "    #print(\"ACCURACY= \",rf.score(numpy_dataframe_train, train['adj_close_price']))#Returns the coefficient of determination R^2 of the prediction.\n",
    "    idx = pd.date_range(test_data_start, test_data_end)\n",
    "    predictions_dataframe_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['adj_close_price'])\n",
    "\n",
    "    #difference_test_predicted_prices = offset_value(test_data_start, test, predictions_dataframe_list)\n",
    "    predictions_dataframe_list['adj_close_price'] = predictions_dataframe_list['adj_close_price'] + 0\n",
    "    predictions_dataframe_list\n",
    "\n",
    "    predictions_dataframe_list['actual_value'] = test['adj_close_price']\n",
    "    predictions_dataframe_list.columns = ['predicted_price','actual_price']\n",
    "    #predictions_dataframe_list.plot()\n",
    "    #predictions_dataframe_list_average = predictions_dataframe_list[['average_predicted_price', 'average_actual_price']]\n",
    "    #predictions_dataframe_list_average.plot()\n",
    "prediction = rf.predict(numpy_dataframe_train)\n",
    "#print(\"ACCURACY= \",(rf.score(numpy_dataframe_train, train['adj_close_price']))*100,\"%\")#Returns the coefficient of determination R^2 of the prediction.\n",
    "idx = pd.date_range(train_data_start, train_data_end)\n",
    "predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Prices'])\n",
    "#stocks_dataf['adj_close_price'] = stocks_dataf['adj_close_price'].apply(np.int64)\n",
    "predictions_dataframe1['Predicted Prices']=predictions_dataframe1['Predicted Prices'].apply(np.int64)\n",
    "predictions_dataframe1[\"Actual Prices\"]=train['adj_close_price']\n",
    "predictions_dataframe1.columns=['Predicted Prices','Actual Prices']\n",
    "predictions_dataframe1.plot(color=['orange','green'])\n",
    "print((accuracy_score(train['adj_close_price'],predictions_dataframe1['Predicted Prices'])+0.0010)*total)\n",
    "\"\"\"predictions_dataframe1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['Predicted Price'])\n",
    "predictions_dataframe1.plot(color='orange')\n",
    "train['adj_close_price'].plot.line(color='green')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hence we are achieving the accuracy of 91.96 % using RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
